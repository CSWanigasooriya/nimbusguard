alloy:
  configMap:
    content: |-
      // LOGS: Collect container logs from Kubernetes and send to Loki
      discovery.kubernetes "pods" {
        role = "pod"
      }

      loki.source.kubernetes "pods" {
        targets = discovery.kubernetes.pods.targets
        forward_to = [loki.process.k8s_labels.receiver]
      }

      loki.process "k8s_labels" {
        stage.static_labels {
          values = {
            cluster = "nimbusguard",
          }
        }
        
        // Extract trace IDs from logs for correlation
        stage.regex {
          expression = ".*traceID=(?P<trace_id>\\w+).*"
        }
        
        stage.labels {
          values = {
            trace_id = "",
          }
        }
        
        forward_to = [loki.write.default.receiver]
      }

      loki.write "default" {
        endpoint {
          url = "http://loki.monitoring.svc.cluster.local:3100/loki/api/v1/push"
        }
      }

      // METRICS: Alloy does ALL the scraping, sends everything to Prometheus via remote_write
      discovery.kubernetes "services" {
        role = "service"
      }

      discovery.kubernetes "pods_for_metrics" {
        role = "pod"
      }

      // Scrape ALL monitoring services (including Prometheus itself)
      discovery.relabel "monitoring_services" {
        targets = discovery.kubernetes.services.targets
        
        rule {
          source_labels = ["__meta_kubernetes_service_annotation_prometheus_io_scrape"]
          regex = "true"
          action = "keep"
        }
        
        rule {
          source_labels = ["__meta_kubernetes_namespace"]
          regex = "monitoring"
          action = "keep"
        }
        
        rule {
          source_labels = ["__meta_kubernetes_service_annotation_prometheus_io_path"]
          action = "replace"
          target_label = "__metrics_path__"
          regex = "(.+)"
          replacement = "${1}"
        }
        
        rule {
          source_labels = ["__meta_kubernetes_service_annotation_prometheus_io_path"]
          regex = ""
          action = "replace"
          target_label = "__metrics_path__"
          replacement = "/metrics"
        }
        
        rule {
          source_labels = ["__address__", "__meta_kubernetes_service_annotation_prometheus_io_port"]
          action = "replace"
          regex = "([^:]+)(?::\\d+)?;(\\d+)"
          replacement = "${1}:${2}"
          target_label = "__address__"
        }
        
        rule {
          source_labels = ["__meta_kubernetes_service_name"]
          action = "replace"
          target_label = "job"
        }
        
        rule {
          source_labels = ["__meta_kubernetes_namespace"]
          action = "replace"
          target_label = "namespace"
        }
      }

      prometheus.scrape "monitoring_services" {
        targets = discovery.relabel.monitoring_services.output
        forward_to = [prometheus.remote_write.default.receiver]
        scrape_interval = "15s"
      }

      // Scrape application pods with prometheus.io/scrape annotation
      discovery.relabel "app_pods" {
        targets = discovery.kubernetes.pods_for_metrics.targets
        
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_scrape"]
          regex = "true"
          action = "keep"
        }
        
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_path"]
          action = "replace"
          target_label = "__metrics_path__"
          regex = "(.+)"
          replacement = "${1}"
        }
        
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_path"]
          regex = ""
          action = "replace"
          target_label = "__metrics_path__"
          replacement = "/metrics"
        }
        
        rule {
          source_labels = ["__address__", "__meta_kubernetes_pod_annotation_prometheus_io_port"]
          action = "replace"
          regex = "([^:]+)(?::\\d+)?;(\\d+)"
          replacement = "${1}:${2}"
          target_label = "__address__"
        }
        
        rule {
          source_labels = ["__meta_kubernetes_pod_name"]
          action = "replace"
          target_label = "pod"
        }
        
        rule {
          source_labels = ["__meta_kubernetes_namespace"]
          action = "replace"
          target_label = "namespace"
        }
        
        rule {
          source_labels = ["__meta_kubernetes_pod_name"]
          action = "replace"
          target_label = "job"
          replacement = "${1}"
        }
      }

      prometheus.scrape "app_pods" {
        targets = discovery.relabel.app_pods.output
        forward_to = [prometheus.remote_write.default.receiver]
        scrape_interval = "15s"
      }

      // Send all metrics to Prometheus via remote_write
      prometheus.remote_write "default" {
        endpoint {
          url = "http://prometheus.monitoring.svc.cluster.local:9090/api/v1/write"
        }
      }

      // TRACES: Receive OTLP traces and send to Tempo
      otelcol.receiver.otlp "default" {
        grpc {
          endpoint = "0.0.0.0:4317"
        }
        http {
          endpoint = "0.0.0.0:4318"
        }
        output {
          traces = [otelcol.processor.k8sattributes.default.input]
        }
      }

      otelcol.processor.k8sattributes "default" {
        passthrough = false
        extract {
          metadata = [
            "k8s.pod.name", 
            "k8s.namespace.name", 
            "k8s.deployment.name",
            "k8s.container.name",
            "k8s.node.name",
          ]
        }
        output {
          traces = [otelcol.processor.batch.default.input]
        }
      }

      otelcol.processor.batch "default" {
        timeout = "1s"
        send_batch_size = 1024
        output {
          traces = [otelcol.exporter.otlp.tempo.input]
        }
      }

      otelcol.exporter.otlp "tempo" {
        client {
          endpoint = "tempo.monitoring.svc.cluster.local:4317"
          tls {
            insecure = true
          }
        }
      }
      
  # Configure proper service exposure for Alloy's own metrics
  service:
    type: ClusterIP
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "12345"
      prometheus.io/path: "/metrics"
  
  # Add proper resource limits
  resources:
    limits:
      cpu: 200m
      memory: 256Mi
    requests:
      cpu: 100m
      memory: 128Mi
